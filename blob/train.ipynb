{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJWB-5dRBRyZ"
      },
      "source": [
        "# steps for training YOLO version 8 AI model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-PE-MOC3Lmx"
      },
      "source": [
        "[![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ibrahimaljalal/YOLOv8/blob/train.ipynb)\n",
        "[![github repo](https://badgen.net/badge/icon/github?icon=github&label)](https://github.com/ibrahimaljalal/YOLOv8)\n",
        "<img src=\"https://www.vectorlogo.zone/logos/opensource/opensource-icon.svg\"  height=\"25\">\n",
        "\n",
        "\n",
        "---\n",
        "**important note:**\n",
        "\n",
        "After you go through this notebook and make your own trained AI model, you could add it to the \"AI_models\" folder in the github repository (in the resources section) and go to main.py file and change best.pt in line 11 to your model's name (after you train your own model it is recommended to change the name of the model from \"best.pt\" to a descriptive name). **The github repository  is a ready to use template for YOLO version 8 ðŸ™‚!**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**prerequisites:**  \n",
        "1. familiar with google colab or at least jupyter notebook (close to colab).\n",
        "2. python programming language.\n",
        "\n",
        "    please note that you could still go through this notebook even if you are not familiar with the above points but you might face some difficulties.\n",
        "\n",
        "\n",
        "**resources:**  \n",
        "   1. [github repository](https://github.com/ibrahimaljalal/yolov8) (we will only be using the \"data_for_training_YOLOv8_models\" folder from this github repository for this colab).\n",
        "   2. [structured data for YOLOv8](https://drive.google.com/drive/folders/1qBdf2eYhHaZd5sahBtCOGG1ghUZXppRF?usp=sharing) (this resourse will not be used in this colab but will provide examples of how the folders should look like or their structure for taining YOLO version 8)\n",
        "   3. [Roboflow Universe](https://universe.roboflow.com/) (the best resource for finding prestructed data for YOLO version 8)\n",
        "\n",
        "**notes:**\n",
        "1. **if you are familiar with YOLOv8, then you could completely skip section 4 - 8**. I have added section 4 - 8 for those who have never used YOLOv8 before and would like to have some basic understanding on how to use their own trained data.\n",
        "2. if you already have a ready to use folder which is structured and labeled for YOLO version 8 (the structure should generally look like section 7), then **skip sections 4 to 8**. if you want to use the example data in this colab, **then do not skip section 4**.\n",
        "3. you could also use any of the pre-made ready to use folders in the compressed file from the google drive in the resources above.\n",
        "4. **if you skip sections 5 to 8 and go through the steps without making any changes, then you should not face any errors.**\n",
        "5. if you want to use your own objects there is a great chance that someone has already gathered and labeled the images for you in [Roboflow website](https://universe.roboflow.com/) as a structured data (you can skip section 4 to 8).\n",
        "6. the folder which contains the data we want to train on is named \"data\" and it will contain a file which is named data.yaml (in some resources it is named config.yaml). most of the resources for YOLOv8 follow this convention.\n",
        "\n",
        "\n",
        "**possible issues:**\n",
        "\n",
        "1. the main issue you might face is with the file paths.\n",
        "2. the colab GPU will shutdown if you open colab in multiple windows.\n",
        "3. colab will only give you 12 hours for free after that it will shutdown. so make sure the time for your training (section 10) is less than 12 hours.\n",
        "4. the train, val, & test variables in the data.yaml file should contain absolute paths for the google drive\n",
        "\n",
        "    **please note that if you go through this notebook step by step (or skip sections 5 to 8) without customizing or adding you own changes, you should not face the above issues.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xbXxj5kCHgt"
      },
      "source": [
        "## 1 - open this file in google colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkzuhI1FzSxz"
      },
      "source": [
        "if you are viewing this file in google colab, then ignore this section.  \n",
        "one way to open this file in colab is to have a google account then go to google drive then select new (up in the left or right click from you mouse) then choose more then select Google Colaboratory.   \n",
        "After you open google colab upload this file (\"File\" > \"Upload notebook\" > then select \"Choose File\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB79cHlRCKVr"
      },
      "source": [
        "## 2 - use the GPU cloud computer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J72m1YmZGk9e"
      },
      "source": [
        "\"Runtime\" > \"Change runtime type\" > switch \"Hardware accelerator\" to GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxNrM1S6Cil9"
      },
      "source": [
        "## 3 - mount your google drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjC9jfZ0Aop2"
      },
      "source": [
        "simply click the \"Mount Drive\" button. if you are not familiar of the place of the button you cloud instead use this command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY3hkkqNBqq7"
      },
      "outputs": [],
      "source": [
        "#mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1mMHYbWzSx6"
      },
      "outputs": [],
      "source": [
        "#your working directory will be in the root of your google drive\n",
        "%cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhvsdci6YqDU"
      },
      "source": [
        "## 4 -  add the github repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljADnBhn3Lm1"
      },
      "source": [
        "we will only use the data folder inside data_for_training_YOLOv8_models/construction_site_objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUIXyKHQFzXu"
      },
      "outputs": [],
      "source": [
        "# add the github repository\n",
        "!git clone https://github.com/ibrahimaljalal/YOLOv8.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YfwWMPwi35N"
      },
      "source": [
        "## 5 - get your own images :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a66XUuLpmUZG"
      },
      "source": [
        "there are mainly two ways to get your own images for the objects you want to train on. either by your own camera or from the internet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk3NY8hKmvbO"
      },
      "source": [
        "### 5.1 get your images from your camera"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFRly3d0m26Q"
      },
      "source": [
        "if you are plaining to get your images from your own camera, then these are the recommended guidelines:\n",
        "\n",
        "1. take pictures from different angles. make sure a high percentage of the pictures are where the object is usually seen in your application.\n",
        "2. if the object has different forms, then try to take all of the possible forms of the object. the number of the images of each form should be proportional to the percentage the form natural occurrence in your application.\n",
        "3. make sure the images are not blurry.\n",
        "4. if the object you want to detect has multiple types, then it is preferred to consider all of the possible types. for an example although German Shepherd & Havanese are both dogs they clearly look different. you could instead focus on the type that is usually seen in your application.\n",
        "5. if there are objects in the environment which look similar to the object you want to detect then either include this objects in another class or try to avoid them in your application.\n",
        "6. make sure the environment lights are the same as your actual application or at least close.\n",
        "7. take the images from the same camera as the one your going to use in your application & do not change the settings (most cameras change their setting depending on the environment light or other factors).\n",
        "8. take as much pictures as you can. the more the better. at least 100 images should be enough for YOLOv8.\n",
        "9. try to avoid transparent objects.\n",
        "10. try to avoid reflective objects.\n",
        "11. unlike most object detection models YOLO does not need negative images\n",
        "12. if what you want to detect is in multiple places in your image, then make sure to label all of the objects. not labeling all of the objects might confuse the algorithm.\n",
        "\n",
        "\n",
        "**please note that not all of the above points are strictly required, but if they are considered we could get the most optimal output.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRDfxq-osPXk"
      },
      "source": [
        "### 5.2 get your images from the internet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SwIR1WO5H8X"
      },
      "source": [
        "if you are planning to download your images from the internet, it is still recommended to consider the guidelines in 5.1 for choosing your images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZzFd4uQsaI6"
      },
      "source": [
        "#### 5.2.1 download from websites with image datasets:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAIstvRws6D3"
      },
      "source": [
        "1. [Roboflow Universe](https://universe.roboflow.com/). **this is the best website for computer vision applications related to object detection**.\n",
        "2. [Kaggle](https://www.kaggle.com/)\n",
        "3. [Open Images Dataset V7](https://storage.googleapis.com/openimages/web/index.html)\n",
        "4. [ImageNet](https://image-net.org/)\n",
        "5. [COCO](https://cocodataset.org/#home)\n",
        "6. [Google Images](https://www.google.com/imghp?hl=en)\n",
        "\n",
        "   Roboflow & Kaggle are usually the best resources for finding YOLOv8 datasets. Kaggle is generally the best resources for finding datasets but roboflow is specialized in computer vision datasets for the top object detection AI models such as YOLOv8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEs7Q60tukJJ"
      },
      "source": [
        "#### 5.2.2 write a script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ-MbmTxuvbF"
      },
      "source": [
        "This section might be one of the most time efficient sections for our process  of making our own trained object detection model (if we did not find the images in Roboflow & Kaggle or any other known website). Especially if we want\n",
        "to use a lot of images and do not want to wast our time in google images and manually download every image that we want to use. this process  will get very tedious."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWM3HDdUv1Q5"
      },
      "outputs": [],
      "source": [
        "#you need more configuration if your are planning to use this library in Windows\n",
        "!pip install simple-image-download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DHWW1kQwPhm"
      },
      "outputs": [],
      "source": [
        "#this script will download images from the internet related to the keywords we have provided.\n",
        "#the images will be very similar to the images we will get if we search in goggle images.\n",
        "#the name of the folder which will contain the images is \"simple_images\"\n",
        "#the \"simple_images\" folder will be in the google drive root (if you did not change your working directory)\n",
        "#since our working directory is in the root because of the previous command in section 3 \"%cd /content/drive/MyDrive\"\n",
        "\n",
        "from simple_image_download import simple_image_download as simd\n",
        "\n",
        "response = simd.simple_image_download\n",
        "\n",
        "keywords = [\"palm\", \"Ù†Ø®Ù„Ø©\", \"palm trees in saudi arabia\"] #every keyword will have its own folder in the \"simple_images\" folder\n",
        "\n",
        "number_of_images = 200 #number_of_images for each keyword. so if we have 5 keywords & number_of_images = 200, then we will download 1000 images\n",
        "\n",
        "\n",
        "for kw in keywords:\n",
        "  response().download(kw,number_of_images)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cMpIWxFBct9"
      },
      "source": [
        "## 6 - label your images:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmKXkBUQkrcj"
      },
      "source": [
        "there are many tools for labeling your images. one of the most common tools is called **labelImg**.\n",
        "to install this program go to your terminal and write:\n",
        "```bash\n",
        "pip install labelImg\n",
        "```\n",
        "to use the tool also got to the terminal and write:\n",
        "```bash\n",
        "labelImg\n",
        "```\n",
        "\n",
        "to know more about labelImg software you could got to YouTube or any other resource.\n",
        "\n",
        "another way to label your images is in roboflow website"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8V3Teu9D9lx"
      },
      "source": [
        "## 7 - data folder structure for YOLOv8:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzqWeRK-ENes"
      },
      "source": [
        "\n",
        "    data\n",
        "        â”œâ”€â”€â”€test\n",
        "        â”‚   â”œâ”€â”€â”€images\n",
        "        â”‚   â””â”€â”€â”€labels\n",
        "        â”œâ”€â”€â”€train\n",
        "        â”‚   â”œâ”€â”€â”€images\n",
        "        â”‚   â””â”€â”€â”€labels\n",
        "        â”œâ”€â”€â”€valid\n",
        "        â”‚   â”œâ”€â”€â”€images\n",
        "        â”‚   â””â”€â”€â”€labels\n",
        "        â””â”€â”€â”€data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngNLEvjaD9zG"
      },
      "source": [
        "## 8 - notes on the data folder structure for YOLOv8:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akIzs0z9E6Nv"
      },
      "source": [
        "1. the root folder (\"data\" folder) and the data.yaml file could be named anything but in our case they are named \"data\" (this seemed to be the convention for YOLOv8). the rest of the folders should have the exact name or you will get an error.\n",
        "2. sometimes you will only see test and train folders or only train.\n",
        "3. the images folder should only contain image files. it is recommended to use .jpeg file format since it uses less space.\n",
        "4. all the images & labels folders in train, test, & valid folders have the same structure. the number of files and files names are the same in both folders the only difference is that the files in images folder have an image extension (such as .jpeg, .png, or tiff etc.) while the files in the labels folder have a .txt extension.\n",
        "5. any file in the labels folder will describe the image in the images folder which has the same name.\n",
        "6. every line in any file in the labels folder will describe one object. if there are for an example 5 lines then there are 5 objects in the image described.\n",
        "7. every line in any file in the labels folder has 5 numbers.\n",
        "   1. the first number is an integer which starts from 0. this number is the class id.\n",
        "   2. to know the id of the class simply go to the data.yaml file to the names variable. this file will equal a list. the first name in the list has an id of 0 and the second name has an id of 1 and so on.\n",
        "   3. the four numbers after the class id are respectively:  \n",
        "    4. the x axis of the center of the rectangle around the object (from 0 to 1)\n",
        "    5. the y axis of the center of the rectangle around the object (from 0 to 1). note that the y axis is from up to down.\n",
        "    6. the width of the rectangle (from 0 to 1)\n",
        "    7. the height of the rectangle (from 0 to 1)\n",
        "\n",
        "8. an example of the data.yaml file looks like this:\n",
        "   ```yaml\n",
        "\n",
        "   test: /content/drive/MyDrive/data/test/images\n",
        "   train: /content/drive/MyDrive/data/train/images\n",
        "   val: /content/drive/MyDrive/data/valid/images\n",
        "\n",
        "   nc: 5\n",
        "   names: ['cat', 'dog', 'pizza', 'car', 'stop sign']\n",
        "   ```\n",
        "   data.yaml notes:\n",
        "      1. the absolute paths of the images in the test, train, & valid folders should be provided to the test, train, & val variables respectively. if you have added the data folder at the root of your google drive then you could past the exact paths as in the above example (assuming you have also named your folder data).\n",
        "      2. nc is short for number of classes. note that this number equals the number of items in the list for the names variable below it.\n",
        "      3. the names variable will contain all of the classes objects that you want to detect in the YOLOv8 algorithm. the first name in the list will have an id of 0 and the second an id of 1 and so on. the id numbers will be in the files in the labels folder in the in the first number of the five numbers of each line.\n",
        "      4. the order of the variable are not important for an example nc could be after names."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jauwwITlBRyf"
      },
      "source": [
        "## 9 - install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_txQtdlABRyg",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics==8.0.20 #this is the stable version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo2QwyrLDQBA"
      },
      "source": [
        "## 10 - train your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7iBDhQQtCig"
      },
      "source": [
        "if you want to train on your own images (skipped sections 4 - 8), then please add the structured folder (should look like section 7) at the root of your google drive and name your folder \"data\" and also name your .yaml file \"data\" (some resources name this file \"config\"). so the path of your .yaml file is /content/drive/MyDrive/data/data.yaml (/content/drive/MyDrive/ is your google drive root). **make sure that the paths of train, test, and val are the same as point 8 in section 8 (this might be one of the common issues you face)**\n",
        "\n",
        "after you train your model the trained model from your working directory (within google drive root) will be at:  \n",
        "**runs/detect/train/weights/best.pt**.  \n",
        "once the best.pt AI model file is used its name is usually changed to a more descriptive name.   \n",
        "if you train again and did not delete the runs folder, then the second model will be in trains 2 folder and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "F0H4q9JyFoVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea48205-d05e-4d21-8545-5fa10551a1a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make sure the github repository is in your drive's root\n"
          ]
        }
      ],
      "source": [
        "#@markdown for testing purpases it is recommended to:\n",
        "\n",
        "#@markdown use the data in the gitub repository (run the code in section 4)\n",
        "\n",
        "#@markdown use yolov8s.pt, and 50 epochs\n",
        "\n",
        "\n",
        "\n",
        "#@title YOLOv8 configuration { vertical-output: true }\n",
        "\n",
        "drive_root_path = \"/content/drive/MyDrive\"\n",
        "gh_repo_path = \"/YOLOv8/data_for_training_YOLOv8_models\\\n",
        "/construction_site_objects\"\n",
        "yolov8_data_path = \"/data/data.yaml\"\n",
        "\n",
        "#@markdown Are you using the data from the github repository (section 4)?\n",
        "data_used = \"yes\" #@param [\"yes\", \"no\"]\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown Model type\n",
        "\n",
        "model_type = \"yolov8s.pt\" #@param [\"yolov8n.pt\", \"yolov8s.pt\",\"yolov8m.pt\",\"yolov8l.pt\",\"yolov8x.pt\"]\n",
        "\n",
        "#@markdown (n=nano, s=small, m=medium, l=large, & x=x-large)\n",
        "\n",
        "#@markdown the nano will not take a long time to train\n",
        "#@markdown but is not accurate & vice versa with x-large.\n",
        "\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown Epochs (the higher the number the more time it takes for training)\n",
        "epochs = 50 #@param {type:\"slider\", min:1, max:500, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "if data_used == \"yes\":\n",
        "    yaml_file_path = drive_root_path+gh_repo_path+yolov8_data_path\n",
        "    print(\"make sure the github repository is in your drive's root\")\n",
        "\n",
        "elif data_used == \"no\":\n",
        "    yaml_file_path = drive_root_path+yolov8_data_path\n",
        "    print(\"since you are using your own data please make\\\n",
        "sure your folder is in the drive root\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amHjBXDSsSFT"
      },
      "outputs": [],
      "source": [
        "#@title start training\n",
        "\n",
        "#note that this command will relatively take a long time. it might take hours if you change the default configurations.\n",
        "\n",
        "#you could skip the \"YOLOv8 configuration\" subsection code and use the default command below (if you used the github repo):\n",
        "#!yolo task=detect mode=train model=yolov8n.pt data = /content/drive/MyDrive/YOLOv8/data_for_training_YOLOv8_models/construction_site_objects/data/data.yaml epochs=25 imgsz=224 plots=True\n",
        "\n",
        "#or if you used your own data:\n",
        "#!yolo task=detect mode=train model=yolov8s.pt data = /content/drive/MyDrive/data/data.yaml epochs=25 imgsz=224 plots=True\n",
        "\n",
        "\n",
        "!yolo task=detect mode=train model=$model_type data = $yaml_file_path epochs=$epochs imgsz=224 plots=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbmpqFyXH8mg"
      },
      "source": [
        "### **some notes on the previous command:**\n",
        "\n",
        "1. it is the main command for training YOLOv8\n",
        "2. this command might take the most amount of time to finish (it might take hours if there were some changes in the parameters)\n",
        "3. the yolo command is available from ultralytics library\n",
        "4. the variables after the \"\\$\" symbol are from the cell before. \"\\$\" is a colab concept (you will get an error if you use \"\\$\" in a terminal. insted use the actuall variables obtained from the cell before).\n",
        "5. most of the main parameters in the yolo command:  \n",
        "\n",
        "    **task**:  \n",
        "    possible values:\n",
        "    detect, segment, classify, pose\n",
        "\n",
        "    **mode**:  \n",
        "    possible values:\n",
        "    train, predict, val\n",
        "\n",
        "    **model**:\n",
        "\n",
        "    possible values if task=detect (most used case):\n",
        "    yolov8n.pt\n",
        "    yolov8s.pt\n",
        "    yolov8m.pt\n",
        "    yolov8l.pt\n",
        "    yolov8x.pt\n",
        "\n",
        "    possible values if task=segment:\n",
        "    yolov8n-seg.pt\n",
        "    yolov8s-seg.pt\n",
        "    yolov8m-seg.pt\n",
        "    yolov8l-seg.pt\n",
        "    yolov8x-seg.pt\n",
        "\n",
        "    possible values if task=classify:\n",
        "    yolov8n-cls.pt\n",
        "    yolov8s-cls.pt\n",
        "    yolov8m-cls.pt\n",
        "    yolov8l-seg.pt\n",
        "    yolov8x-cls.pt\n",
        "\n",
        "    possible values if task=pose:\n",
        "    yolov8n-pose.pt\n",
        "    yolov8s-pose.pt\n",
        "    yolov8m-pose.pt\n",
        "    yolov8l-pose.pt\n",
        "    yolov8x-pose.pt\n",
        "\n",
        "    notes:  \n",
        "    n=nano\n",
        "    s=small\n",
        "    m=medium\n",
        "    l=large\n",
        "    x=x-large\n",
        "\n",
        "    n will not take long to train but it will not be very accurate.  \n",
        "    the opposite is true with x. depending on your need you could choose the suitable model.  \n",
        "\n",
        "    the rest of the abbreviations are self-explanatory and if you want to know the difference between  \n",
        "    detection, segmentation, classification, and Pose you could simply search in the internet.  \n",
        "    our main focus in this notebook is on detection.\n",
        "\n",
        "    **data**:  \n",
        "    simply add the path of your data.yaml file. to avoid some possible issues use the absolute path.\n",
        "\n",
        "    **epochs**:  \n",
        "    possible values: positive integer\n",
        "\n",
        "    notes:  \n",
        "    If you want your model to be more accurate, increase this number. generally at least 25 is an acceptable number.\n",
        "\n",
        "\n",
        "\n",
        "6. results:\n",
        "\n",
        "    all of the results of the previous command will be saved in great details in a folder called **runs** in your working directory.  \n",
        "\n",
        "    the model name is **best.pt**\n",
        "    it will be saved in:  \n",
        "    runs/detect/train/weights/best.pt\n",
        "\n",
        "    this model will be used in the main.py file. we will change its name from best.pt to YOLOv8&lt;then some description&gt;.pt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HPgNpLZzSyA"
      },
      "source": [
        "## 11 - use the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLY5lfQDzSyA"
      },
      "source": [
        "You could use the model (best.pt file in runs/detect/train/weights) in the github repository (in the resources subsection at the beginning of this colab) or test it in this colab.\n",
        "\n",
        "**please note that the only file we are mainly interested in after training the AI model in this colab is the \"best.pt\" file. this is the only file we need for the github repository.**\n",
        "\n",
        "---\n",
        "\n",
        "### test the model in this colab:\n",
        "\n",
        "The result will be saved in the google drive root in runs/detect/predict.  \n",
        "just like the \"train\" folder if you run the below code again you will get predict2 and so on.  \n",
        "you could upload your model  in roboflow website and easily test it after you make an account.\n",
        "\n",
        "please note that if you predict without changing the training parameters you will not get a very accurate result since we only took few minutes for training. **still the results are impressive ðŸ™‚!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dggD1nIkTrW0"
      },
      "outputs": [],
      "source": [
        "# test the model in this colab:\n",
        "\n",
        "#the source variable could be an image from your drive or a url\n",
        "source = \"https://t4.ftcdn.net/jpg/03/64/36/95/360_F_364369573_uMPBzv3PdmuIZVsSluD2SlpdQ1Cs1H4m.jpg\"\n",
        "model =\"/content/drive/MyDrive/runs/detect/train/weights/best.pt\"\n",
        "\n",
        "\n",
        "\n",
        "!yolo predict model=$model source=$source save=true conf=0.60"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "2xbXxj5kCHgt",
        "cB79cHlRCKVr",
        "lxNrM1S6Cil9",
        "rhvsdci6YqDU",
        "_YfwWMPwi35N",
        "0cMpIWxFBct9",
        "e8V3Teu9D9lx",
        "ngNLEvjaD9zG",
        "jauwwITlBRyf",
        "Oo2QwyrLDQBA",
        "7HPgNpLZzSyA"
      ],
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}